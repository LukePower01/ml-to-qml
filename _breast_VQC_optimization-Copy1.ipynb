{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22bead26-48ee-44c5-9b69-8fcb17bbb777",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from qiskit_ibm_provider import IBMProvider\n",
    "provider = IBMProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1965f14d-2665-47ea-b88f-11649c648fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Qiskit \n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor, VQR\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_algorithms.optimizers import COBYLA, L_BFGS_B, ADAM, SLSQP, AQGD\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "# Visualization libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from qiskit.visualization import plot_histogram\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c45833-e68a-48bb-a7d5-c269465dbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "features = breast_cancer_data.data\n",
    "labels = breast_cancer_data.target\n",
    "features = MinMaxScaler().fit_transform(features)\n",
    "algorithm_globals.random_seed = 4701\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, train_size = 0.8, random_state = algorithm_globals.random_seed)\n",
    "num_features = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b4d8c2-da95-4c5e-bc47-080960a06d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ece2e7-03d8-4cee-b6a9-64a09a66e0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e730260d-0f61-4046-bc36-6c0c9fcbd6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027f6727-5dd4-46bb-9ab9-0b07ff844207",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=COBYLA(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=features.shape[1], reps =1 )\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac9d5ce-085f-462f-a08a-c72956c3939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc34141-fda1-4a3a-a97c-c38454def3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "\n",
    "# objective function characterizes the distance between the predictions and known labeled data.\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "             \n",
    "# Append the value of the objective function to an array so we \n",
    "# can plot the iteration verses the objective function value\n",
    "             \n",
    "             clear_output(wait=True)\n",
    "             objective_func_vals.append(obj_func_eval)\n",
    "             plt.title('Objective function value against Iteration- COBYLA & RealAmplitudes')\n",
    "             plt.xlabel('Iteration')\n",
    "             plt.ylabel('Objective function value')\n",
    "             plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "             \n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3ae2d-8d60-456d-8090-8d908c65712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VQC(\n",
    "    sampler = sampler, \n",
    "    feature_map = feature_map,\n",
    "    ansatz = ansatz, \n",
    "    optimizer = optimizer, \n",
    "    callback = callback_graph,)\n",
    "\n",
    "# Clear objective value history\n",
    "objective_func_vals = []\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features,train_labels)\n",
    "elsapsed_time = time.time() - start \n",
    "\n",
    "print(f'Training time: {elsapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d4c8c-fd28-4af8-8144-19ff3df19beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vqc.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebfce0-7a98-422c-a633-f1b7e9b26003",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=ADAM(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=4, reps =1 )\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f31ddf-05d0-410d-af6c-99ef25b5095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "\n",
    "# objective function characterizes the distance between the predictions and known labeled data.\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "             \n",
    "# Append the value of the objective function to an array so we \n",
    "# can plot the iteration verses the objective function value\n",
    "             \n",
    "             clear_output(wait=True)\n",
    "             objective_func_vals.append(obj_func_eval)\n",
    "             plt.title('Objective function value against Iteration Adam Optimizer')\n",
    "             plt.xlabel('Iteration')\n",
    "             plt.ylabel('Objective function value')\n",
    "             plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "             \n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e4632-caae-444d-bd23-7121e88f5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=SLSQP(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=4, reps =1 )\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54873d7-ba9d-4cfb-b64f-a333d1c0a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "             \n",
    "             clear_output(wait=True)\n",
    "             objective_func_vals.append(obj_func_eval)\n",
    "             plt.title('Objective function value against Iteration SLSQP Optimizer')\n",
    "             plt.xlabel('Iteration')\n",
    "             plt.ylabel('Objective function value')\n",
    "             plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "             \n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8e5a1-8b37-430d-8a56-c384787c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VQC(\n",
    "    sampler = sampler, \n",
    "    feature_map = feature_map,\n",
    "    ansatz = ansatz, \n",
    "    optimizer = optimizer, \n",
    "    callback = callback_graph,)\n",
    "\n",
    "objective_func_vals = []\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features,train_labels)\n",
    "elsapsed_time = time.time() - start \n",
    "\n",
    "print(f'Training time: {elsapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb4ee0-3f34-4f33-91dc-f87343129e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vqc.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088178d-49f2-4e51-8190-b4834f5533eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=COBYLA(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=4, reps =1 )\n",
    "ansatz = EfficientSU2(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce66c4e-dcb1-4c01-b940-9ea47901fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "             \n",
    "             clear_output(wait=True)\n",
    "             objective_func_vals.append(obj_func_eval)\n",
    "             plt.title('Objective function value against Iteration EFF Ansatz')\n",
    "             plt.xlabel('Iteration')\n",
    "             plt.ylabel('Objective function value')\n",
    "             plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "             \n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ee350-1afb-44e4-b628-208c0dbe6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VQC(\n",
    "    sampler = sampler, \n",
    "    feature_map = feature_map,\n",
    "    ansatz = ansatz, \n",
    "    optimizer = optimizer, \n",
    "    callback = callback_graph,)\n",
    "\n",
    "objective_func_vals = []\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features,train_labels)\n",
    "elsapsed_time = time.time() - start \n",
    "\n",
    "print(f'Training time: {elsapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299a0ef-6af1-4e0b-a713-88f6c7aad268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba332606-b3cd-49be-8d88-23ce5ed8ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=SLSQP(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=4, reps =1 )\n",
    "ansatz = EfficientSU2(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d5dd9-830e-4d5e-8771-baed36f507d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_func_vals = []\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "             \n",
    "             clear_output(wait=True)\n",
    "             objective_func_vals.append(obj_func_eval)\n",
    "             plt.title('Objective function value against Iteration EFF Ansatz')\n",
    "             plt.xlabel('Iteration')\n",
    "             plt.ylabel('Objective function value')\n",
    "             plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "             \n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0410f-6184-4c03-b290-736a7c22f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc = VQC(\n",
    "    sampler = sampler, \n",
    "    feature_map = feature_map,\n",
    "    ansatz = ansatz, \n",
    "    optimizer = optimizer, \n",
    "    callback = callback_graph,)\n",
    "\n",
    "objective_func_vals = []\n",
    "\n",
    "start = time.time()\n",
    "vqc.fit(train_features,train_labels)\n",
    "elsapsed_time = time.time() - start \n",
    "\n",
    "print(f'Training time: {elsapsed_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfd9f0-7516-4447-92ed-bac9c2343459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vqc.score(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a326d-939e-42db-aa56-afd400f47ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing DataFrames each missing one feature\n",
    "dfs = {\n",
    "    \"Full Features\": df,\n",
    "    \"Missing Sepal Length\": df.drop(columns=['sepal length (cm)']),\n",
    "    \"Missing Sepal Width\": df.drop(columns=['sepal width (cm)']),\n",
    "    \"Missing Petal Length\": df.drop(columns=['petal length (cm)']),\n",
    "    \"Missing Petal Width\": df.drop(columns=['petal width (cm)']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d06bc-d557-4445-acf1-23df25a4563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=COBYLA(maxiter=100)\n",
    "feature_map = ZZFeatureMap(feature_dimension=4, reps =1 )\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cb80b-b30f-4cef-9584-585bead19075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_graph(weights, obj_func_eval):\n",
    "    global current_dataset\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals_dict[current_dataset].append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    \n",
    "    for description, obj_vals in objective_func_vals_dict.items():\n",
    "        if obj_vals:  # Plot only if there are values\n",
    "            iterations = range(len(obj_vals))\n",
    "            plt.plot(iterations, obj_vals, label=description)\n",
    "            # Annotate the most recent point\n",
    "            plt.annotate(f\"{obj_vals[-1]:.2f}\",\n",
    "                         (iterations[-1], obj_vals[-1]),\n",
    "                         textcoords=\"offset points\",\n",
    "                         xytext=(0,10),\n",
    "                         ha='center',\n",
    "                         fontsize=8)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58163376-a154-4e6a-a56a-05ad0377d899",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_features = breast_cancer_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0dd25d-3cf0-44ee-b0e0-d0e0591e3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_descriptions = [\"Full Features\", \"Missing Sepal Length\", \"Missing Sepal Width\", \"Missing Petal Length\",\n",
    "                     \"Missing Petal Width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ca138-6491-4bd9-b735-bbde91724705",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times = {}\n",
    "vqc_scores = {}\n",
    "plt.clf()\n",
    "objective_func_vals_dict = {\n",
    "    \"Full Features\": [],\n",
    "    \"Missing Sepal Length\": [],\n",
    "    \"Missing Sepal Width\": [],\n",
    "    \"Missing Petal Length\": [],\n",
    "    \"Missing Petal Width\": []\n",
    "}\n",
    "\n",
    "for i, description in enumerate(data_descriptions):\n",
    "    features = full_features a\n",
    "    if i == 0:\n",
    "        features = features # Run VQC on full feature set first\n",
    "    else:\n",
    "        features = np.delete(features, i-1, axis = 1)\n",
    "    \n",
    "    num_features = features.shape[1]  # Adjusted to current feature count\n",
    "    current_dataset = description\n",
    "    \n",
    "    # Dynamically adjust the feature map and ansatz for the current number of features\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "    ansatz = EfficientSU2(num_qubits=num_features, reps=3)\n",
    "    \n",
    "    \n",
    "    # Prepare features and labels\n",
    "    features_scaled = MinMaxScaler().fit_transform(features)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features_scaled, labels, train_size=0.8, random_state=algorithm_globals.random_seed)\n",
    "    \n",
    "    # Initialize VQC for the adjusted feature map and ansatz\n",
    "    vqc = VQC(\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer,\n",
    "        callback=callback_graph\n",
    "    )\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    vqc.fit(train_features, train_labels)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Scores\n",
    "    train_score_quantum = vqc.score(train_features, train_labels)\n",
    "    test_score_quantum = vqc.score(test_features, test_labels)\n",
    "    vqc_scores[description] = {'Training Score': train_score_quantum, 'Test Score': test_score_quantum}\n",
    "\n",
    "    # Store elapsed time for training\n",
    "    training_times[description] = elapsed_time\n",
    "    print(f\"Training time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5245b-d4e8-4dcc-a3b0-52313507d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_test_score_quantum = vqc_scores['Full Features']['Test Score']\n",
    "quantum_differences = {desc: vqc_scores[desc]['Test Score'] - full_feature_test_score_quantum \n",
    "                       for desc in vqc_scores if desc != \"Full Features\"}\n",
    "descriptions_quantum = list(quantum_differences.keys())\n",
    "quantum_diff_values = list(quantum_differences.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df66a56-f397-4f84-8380-ab3eb03c6fb1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(descriptions_quantum, quantum_diff_values, color='blue')\n",
    "plt.xlabel('Configuration')\n",
    "plt.ylabel('Difference in Test Accuracy from Full Features')\n",
    "plt.title('Impact of Missing Features on Quantum Model Test Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8eb19-0887-4caa-af59-b42a871c4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores and differences for quantum models\n",
    "print(\"Quantum Scores and Differences from Full Features:\")\n",
    "for description, scores in vqc_scores.items():\n",
    "        test_score_quantum = scores['Test Score']\n",
    "        difference_quantum = test_score_quantum - full_feature_test_score_quantum \n",
    "        print(f\"{description}:\")\n",
    "        print(f\"  - Quantum VQC on the training dataset: {scores['Training Score']:.2f}\")\n",
    "        print(f\"  - Quantum VQC on the test dataset:     {test_score_quantum:.2f}\")\n",
    "        print(f\"  - Difference from Full Features test score: {difference_quantum:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3ff1b-1557-4ec4-8f8b-02591097bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for description, scores in vqc_scores.items():\n",
    "    test_score = scores['Test Score']\n",
    "    difference_quantum = test_score - full_feature_test_score_quantum\n",
    "    # Calculating the difference as a percentage\n",
    "    difference_percentage = (difference_quantum / full_feature_test_score_quantum) * 100 if full_feature_test_score_quantum else 0\n",
    "    data.append({\"Description\": description, \n",
    "                 \"Test Score\": test_score, \n",
    "                 \"Difference from Full Features\": difference_quantum,\n",
    "                 \"Percentage Difference from Full Features\": difference_percentage})\n",
    "\n",
    "# Creating the DataFrame\n",
    "quantum_scores_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24590a0c-6737-44ea-839b-b5350d558d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238650f2-5d17-4aaf-97d9-0987b7409a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming quantum_scores_df is your DataFrame and it contains the 'Full Features' data\n",
    "\n",
    "# Extract the 'Full Features' test score for reference\n",
    "full_features_test_score = quantum_scores_df[quantum_scores_df['Description'] == 'Full Features']['Test Score'].values[0]\n",
    "\n",
    "# Creating the plots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Test Scores\n",
    "ax[0].barh(categories, test_scores, color='blue')\n",
    "ax[0].set_title('Test Dataset Scores')\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].axvline(x=full_features_test_score, color='red', linestyle='--', label='Full Features Score')  # Vertical line for Full Features score\n",
    "ax[0].legend()\n",
    "\n",
    "# Differences from Full Features\n",
    "ax[1].barh(categories, differences, color='green')\n",
    "ax[1].set_title('Difference from Full Features')\n",
    "ax[1].set_xlim(min(differences)-0.05, max(differences)+0.05)\n",
    "ax[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax[1].axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "# Percentage Differences from Full Features\n",
    "ax[2].barh(categories, percent_differences, color='green')\n",
    "ax[2].set_title('% Difference from Full Features')\n",
    "ax[2].set_xlim(min(percent_differences)-5, max(percent_differences)+5)\n",
    "ax[2].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax[2].axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f3342-d94a-474a-9022-f5f1b293a3cb",
   "metadata": {},
   "source": [
    "## Classical scores\n",
    "\n",
    "Full Features:\n",
    "  - Classical SVC on the training dataset: 0.98\n",
    "  - Classical SVC on the test dataset:     0.93\n",
    "  - Difference from Full Features test score: 0.00\n",
    "\n",
    "Missing Sepal Length:\n",
    "  - Classical SVC on the training dataset: 0.98\n",
    "  - Classical SVC on the test dataset:     0.93\n",
    "  - Difference from Full Features test score: 0.00\n",
    "\n",
    "Missing Sepal Width:\n",
    "  - Classical SVC on the training dataset: 0.98\n",
    "  - Classical SVC on the test dataset:     0.90\n",
    "  - Difference from Full Features test score: 0.03\n",
    "\n",
    "Missing Petal Length:\n",
    "  - Classical SVC on the training dataset: 0.97\n",
    "  - Classical SVC on the test dataset:     0.93\n",
    "  - Difference from Full Features test score: 0.00\n",
    "\n",
    "Missing Petal Width:\n",
    "  - Classical SVC on the training dataset: 0.95\n",
    "  - Classical SVC on the test dataset:     0.90\n",
    "  - Difference from Full Features test score: 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44527bb-b742-41e7-945e-3ff021027603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing classical SVC data for visualization\n",
    "classical_svc_data = {\n",
    "    \"Description\": [\n",
    "        \"Full Features\",\n",
    "        \"Missing Sepal Length\",\n",
    "        \"Missing Sepal Width\",\n",
    "        \"Missing Petal Length\",\n",
    "        \"Missing Petal Width\"\n",
    "    ],\n",
    "    \"Training Score\": [0.98, 0.98, 0.98, 0.97, 0.95],\n",
    "    \"Test Score\": [0.93, 0.93, 0.90, 0.93, 0.90],\n",
    "    \"Difference from Full Features\": [0.00, 0.00, -0.03, 0.00, -0.03]\n",
    "}\n",
    "\n",
    "# Creating DataFrame\n",
    "classical_svc_df = pd.DataFrame(classical_svc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1cea0-56e7-4c63-b3c1-715e50ad3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the classical_svc_data is provided as above, let's update it to include the percentage difference\n",
    "\n",
    "# Update the classical_svc_data dictionary to include the calculation of percentage differences\n",
    "for i, score in enumerate(classical_svc_data['Test Score']):\n",
    "    # Calculating the percentage difference from the Full Features test score\n",
    "    if classical_svc_data['Description'][i] == \"Full Features\":\n",
    "        full_feature_test_score_classical = score\n",
    "    difference = classical_svc_data['Difference from Full Features'][i]\n",
    "    percentage_difference = (difference / full_feature_test_score_classical) * 100 if full_feature_test_score_classical else 0\n",
    "    # Append the percentage difference to a new list if it's not the initial setup\n",
    "    if 'Percentage Difference from Full Features' not in classical_svc_data:\n",
    "        classical_svc_data['Percentage Difference from Full Features'] = []\n",
    "    classical_svc_data['Percentage Difference from Full Features'].append(percentage_difference)\n",
    "\n",
    "# Creating the updated DataFrame with percentage differences\n",
    "classical_svc_df = pd.DataFrame(classical_svc_data)\n",
    "\n",
    "classical_svc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64956fb-6d8d-4eb6-846c-389c795a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Full Features' test score for reference\n",
    "full_features_test_score_classical = classical_svc_df[classical_svc_df['Description'] == 'Full Features']['Test Score'].values[0]\n",
    "\n",
    "# Extracting categories and scores from the DataFrame\n",
    "categories_classical = classical_svc_df['Description']\n",
    "test_scores_classical = classical_svc_df['Test Score']\n",
    "differences_classical = classical_svc_df['Difference from Full Features']\n",
    "percent_differences_classical = classical_svc_df['Percentage Difference from Full Features']\n",
    "\n",
    "# Creating the plots with an additional subplot for percentage differences\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Adjusted for three subplots\n",
    "\n",
    "# Test Scores\n",
    "ax[0].barh(categories_classical, test_scores_classical, color='lightgreen')\n",
    "ax[0].set_title('Classical SVC Test Dataset Scores')\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax[0].axvline(x=full_features_test_score_classical, color='red', linestyle='--', label='Full Features Score')  # Vertical line for Full Features score\n",
    "ax[0].legend()\n",
    "\n",
    "# Absolute Differences from Full Features\n",
    "ax[1].barh(categories_classical, differences_classical, color='salmon')\n",
    "ax[1].set_title('Absolute Difference from Full Features (Classical SVC)')\n",
    "ax[1].set_xlim(min(differences_classical)-0.05, max(differences_classical)+0.05)\n",
    "ax[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax[1].axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "# Percentage Differences from Full Features\n",
    "ax[2].barh(categories_classical, percent_differences_classical, color='orange')\n",
    "ax[2].set_title('Percentage Difference from Full Features (Classical SVC)')\n",
    "ax[2].set_xlim(np.min(percent_differences_classical) - 5, np.max(percent_differences_classical) + 5)\n",
    "ax[2].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax[2].axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea2259-a23f-4f29-82d9-98e86fab70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = quantum_scores_df['Description']  \n",
    "percent_differences_quantum = quantum_scores_df['Percentage Difference from Full Features']\n",
    "percent_differences_classical = classical_svc_df['Percentage Difference from Full Features']\n",
    "\n",
    "# Creating the overlay plot with correct representation of positive and negative changes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Setting positions for each category's bar groups\n",
    "positions = np.arange(len(categories))\n",
    "\n",
    "# Plotting percentage differences for quantum and classical with correct +/- representation\n",
    "ax.barh(positions - 0.2, percent_differences_quantum, height=0.4, label='Quantum', color='green')\n",
    "ax.barh(positions + 0.2, percent_differences_classical, height=0.4, label='Classical', color='orange')\n",
    "\n",
    "# Setting labels, title, and customizing the axes and legend\n",
    "ax.set(yticks=positions, yticklabels=categories)\n",
    "ax.set_title('Percentage Difference from Full Features: Quantum vs Classical')\n",
    "ax.set_xlabel('Percentage Difference from Full Features (%)')\n",
    "ax.legend()\n",
    "\n",
    "# Adding grid lines and emphasizing the line at x = 0 to highlight no change\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02d7d5-c0d6-4f38-b546-a67d784c3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a47af2b-7c2f-4d40-a19c-448478b54344",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callback_graph(weights, obj_func_eval):\n",
    "    global current_dataset\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals_dict[current_dataset].append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against Iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    \n",
    "    for description, obj_vals in objective_func_vals_dict.items():\n",
    "        if obj_vals:  # Plot only if there are values\n",
    "            iterations = range(len(obj_vals))\n",
    "            plt.plot(iterations, obj_vals, label=description)\n",
    "            # Annotate the most recent point\n",
    "            plt.annotate(f\"{obj_vals[-1]:.2f}\",\n",
    "                         (iterations[-1], obj_vals[-1]),\n",
    "                         textcoords=\"offset points\",\n",
    "                         xytext=(0,10),\n",
    "                         ha='center',\n",
    "                         fontsize=8)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a1860-8671-47bd-840d-954fa9609fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times = {}\n",
    "vqc_scores = {}\n",
    "plt.clf()\n",
    "objective_func_vals_dict = {\n",
    "    \"Full Features\": [],\n",
    "    \"Missing Sepal Length\": [],\n",
    "    \"Missing Sepal Width\": [],\n",
    "    \"Missing Petal Length\": [],\n",
    "    \"Missing Petal Width\": []\n",
    "}\n",
    "\n",
    "for i, description in enumerate(data_descriptions):\n",
    "    features = full_features\n",
    "    if i == 0:\n",
    "        features = features # Run VQC on full feature set first\n",
    "    else:\n",
    "        features = np.delete(features, i-1, axis = 1)\n",
    "    \n",
    "    num_features = features.shape[1]  # Adjusted to current feature count\n",
    "    current_dataset = description\n",
    "    \n",
    "    # Dynamically adjust the feature map and ansatz for the current number of features\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
    "    ansatz = EfficientSU2(num_qubits=num_features, reps=4)\n",
    "    \n",
    "    \n",
    "    # Prepare features and labels\n",
    "    features_scaled = MinMaxScaler().fit_transform(features)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features_scaled, labels, train_size=0.8, random_state=algorithm_globals.random_seed)\n",
    "    \n",
    "    # Initialize VQC for the adjusted feature map and ansatz\n",
    "    vqc = VQC(\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=SLSQP(maxiter=100),\n",
    "        callback=callback_graph\n",
    "    )\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    vqc.fit(train_features, train_labels)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Scores\n",
    "    train_score_quantum = vqc.score(train_features, train_labels)\n",
    "    test_score_quantum = vqc.score(test_features, test_labels)\n",
    "    vqc_scores[description] = {'Training Score': train_score_quantum, 'Test Score': test_score_quantum}\n",
    "\n",
    "    # Store elapsed time for training\n",
    "    training_times[description] = elapsed_time\n",
    "    print(f\"Training time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f538bed-530c-4dfe-bf8e-e3455f6cd6dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_runtime = end_time - start_time\n",
    "print(f\"Total Notebook Runtime: {total_runtime} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a27020-11e5-4733-be5c-cc388626c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_test_score_quantum = vqc_scores['Full Features']['Test Score']\n",
    "quantum_differences = {desc: vqc_scores[desc]['Test Score'] - full_feature_test_score_quantum \n",
    "                       for desc in vqc_scores if desc != \"Full Features\"}\n",
    "descriptions_quantum = list(quantum_differences.keys())\n",
    "quantum_diff_values = list(quantum_differences.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39b722-ea12-4ec9-ae86-e784f425c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(descriptions_quantum, quantum_diff_values, color='blue')\n",
    "plt.xlabel('Configuration')\n",
    "plt.ylabel('Difference in Test Accuracy from Full Features')\n",
    "plt.title('Impact of Missing Features on Quantum Model Test Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c86ee-e0d4-40cb-a938-7f6967ebf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores and differences for quantum models\n",
    "print(\"Quantum Scores and Differences from Full Features:\")\n",
    "for description, scores in vqc_scores.items():\n",
    "        test_score_quantum = scores['Test Score']\n",
    "        difference_quantum = test_score_quantum - full_feature_test_score_quantum \n",
    "        print(f\"{description}:\")\n",
    "        print(f\"  - Quantum VQC on the training dataset: {scores['Training Score']:.2f}\")\n",
    "        print(f\"  - Quantum VQC on the test dataset:     {test_score_quantum:.2f}\")\n",
    "        print(f\"  - Difference from Full Features test score: {difference_quantum:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b8abb-4efc-41df-b25c-0011a5f1cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(vqc, test_features, test_labels,\n",
    "                           n_repeats=30,\n",
    "                           random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfad68-71cd-4755-9228-5dfd6d9e8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{breast_cancer_data.feature_names[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca88cfc-b55a-45b6-aec9-4d0cb4bca118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_names = breast_cancer_data.feature_names\n",
    "\n",
    "# Indices of features, sorted by importance\n",
    "sorted_idx = r.importances_mean.argsort()[::-1]\n",
    "\n",
    "# Prepare labels and their corresponding importance scores and std deviations\n",
    "labels = np.array(feature_names)[sorted_idx]\n",
    "importance_means = r.importances_mean[sorted_idx]\n",
    "importance_stds = r.importances_std[sorted_idx]\n",
    "\n",
    "# Filter based on your criteria for significance\n",
    "significant_indices = [i for i in range(len(importance_means)) if importance_means[i] - 2 * importance_stds[i] > 0]\n",
    "significant_labels = labels[significant_indices]\n",
    "significant_means = importance_means[significant_indices]\n",
    "significant_stds = importance_stds[significant_indices]\n",
    "\n",
    "# Plot\n",
    "plt.barh(significant_labels, significant_means, xerr=significant_stds, align='center')\n",
    "plt.xlabel('Mean Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
